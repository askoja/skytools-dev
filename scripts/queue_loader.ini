
[mega_dispatcher]

job_name =
logfile =
pidfile =

db = 

rename_tables = 

[DEFAULT]

# fields - which fields to send through
#fields = col1, col2, col3:renamed3
#fields = *

# table_mode - how to handle a table
#
# ignore - ignore this table
# direct - update table directly
# split - split data into partitions
#table_mode = ignore

# split_mode - how to split, if requested
#
# by-batch-time: use batch time for splitting
# by-event-time: use event time for splitting
# by-date-field:fld - use fld for splitting
#split_mode = by-batch-time

# split_part - partition name format
#
# %(table_name)s %(year)s %(month)s %(day)s %(hour)s
#split_part = %(table_name)s_%(year)s_%(month)s_%(day)s

# split_part_template - How to create new partition tables
#
# Available fields:
# %(part)s
# %(parent)s
# %(pkey)s
#
### Non-inherited partitions
#split_part_template =
#    create table %%(part)s (like %%(parent)s);
#    alter table only %%(part)s add primary key (%%(pkey)s);
#
### Inherited partitions
#split_part_template = 
#    create table %%(part)s () inherits (%%(parent)s);
#    alter table only %%(part)s add primary key (%%(pkey)s);


# row_mode - How to apply the events
#
# plain - each event creates SQL statement to run
# keep_latest - change updates to DELETE + INSERT
# keep_all - change updates to inserts, ignore deletes
# bulk - instead of statement-per-row, do bulk updates
#row_mode = plain


# bulk_mode - How to do the bulk update
#
# correct - inserts as COPY into table,
#           update as COPY into temp table and single UPDATE from there
#           delete as COPY into temp table and single DELETE from there
# delete - as 'correct', but do update as DELETE + COPY
# merged - as 'delete', but merge insert rows with update rows
#bulk_mode=correct

[table public.foo]
mode = 
create_sql =

# partition by date field
# partition by batch time

# apply all
# keep_all
# apply latest

cube:

table:

bulk:






[udata_dispatcher]
job_name          = test_move

src_db            = dbname=sourcedb_test
dst_db            = dbname=dataminedb_test

pgq_queue_name    = OrderLog

logfile           = ~/log/%(job_name)s.log
pidfile           = ~/pid/%(job_name)s.pid

# where to put data.  when partitioning, will be used as base name
dest_table = orders

# date field with will be used for partitioning
# special value: _EVTIME - event creation time
part_column = start_date

#fields = *
#fields = id, name
#fields = id:newid, name, bar:baz


# template used for creating partition tables
# _DEST_TABLE
part_template     = 
    create table _DEST_TABLE () inherits (orders);
    alter table only _DEST_TABLE add constraint _DEST_TABLE_pkey primary key (id);
    grant select on _DEST_TABLE to group reporting;


